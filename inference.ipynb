{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qblocks/anaconda3/envs/mt4r/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pl_model import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "params = yaml.safe_load(open(\"params.yaml\", \"r\"))[\"trainer\"]\n",
    "args_list = []\n",
    "\n",
    "for k, v in params.items():\n",
    "    args_list.append(f\"--{k}={v}\")\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--max_epochs\", type=int, default=1)\n",
    "parser.add_argument(\"--train_batch_size\", type=int, default=32)\n",
    "parser.add_argument(\"--val_batch_size\", type=int, default=64)\n",
    "parser.add_argument(\"--accelerator\", type=str, default=\"cpu\")\n",
    "parser.add_argument(\"--filename\", type=str, default=None)\n",
    "parser.add_argument(\"--wandb_project_name\", type=str, default=None)\n",
    "parser = BertClassifier.add_model_specific_args(parser)\n",
    "args = parser.parse_args(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(64, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=128, out_features=28, bias=True)\n",
       "  (negative_sample_scaler): Sequential(\n",
       "    (0): Linear(in_features=28, out_features=28, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=28, out_features=28, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier.load_from_checkpoint('model_ckpt/best_model-v10.ckpt')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.trained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import CustomDataset\n",
    "\n",
    "test_dataset = CustomDataset(args.filename, split=\"test\", max_len=args.max_len)\n",
    "it = iter(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "vocab = test_dataset.tokenizer.vocab\n",
    "idx2char = list(vocab.keys())\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_char(sample: dict, model: torch.nn.Module, idx2char: list, vocab: dict):\n",
    "    input_ids = sample['input_ids'].unsqueeze(0)\n",
    "    attention_mask = sample['attention_mask'].unsqueeze(0)\n",
    "    output = torch.softmax(model(input_ids, attention_mask, torch.zeros(1, 28)), dim=-1)\n",
    "    topk = output[0,sample['labels'] != -100].topk(2)\n",
    "    scores = topk.values\n",
    "    indices = topk.indices\n",
    "    indices_n_scores = zip(indices.view(-1).tolist(), scores.view(-1).tolist())\n",
    "    ordered_set = OrderedDict()\n",
    "\n",
    "    for k, v in indices_n_scores:\n",
    "        if k not in ordered_set:\n",
    "            ordered_set[k] = v\n",
    "\n",
    "    predictions = list(map(lambda x: idx2char[x], ordered_set.keys()))\n",
    "    ground_truth = [idx2char[x] for x in sample['labels'][sample['labels'] != -100].tolist()]\n",
    "    input = [idx2char[x] if (x != vocab['<MASK>']) else '_' for x in input_ids[input_ids != vocab['<PAD>']].tolist()]\n",
    "    print(f'Input: {input}')\n",
    "    print(f'Ground Truth: {ground_truth}')\n",
    "    print(f'Predictions: {predictions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81302ba2cd77478e8bca6c39d99795a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='x', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.f(x: int)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "it = iter(test_dataset)\n",
    "def f(x: int):\n",
    "    sample = next(it)\n",
    "    predict_char(sample, model, idx2char, vocab)\n",
    "    print('------')\n",
    "\n",
    "interact(f, x=range(0, len(test_dataset), 1))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict(zip('abcedfghijklmnopqrstuvwxyz', range(2, 28)))\n",
    "idx2char = list('__abcedfghijklmnopqrstuvwxyz')\n",
    "vocab['_'] = 1\n",
    "\n",
    "def tensorify(word, negative_samples):\n",
    "    word = torch.tensor([vocab[c] for c in word])\n",
    "    negative_sample = [0] * 28\n",
    "    for c in negative_samples:\n",
    "        negative_sample[vocab[c]] = 1\n",
    "    negative_sample = torch.tensor(negative_sample).float()\n",
    "    attention_mask = torch.tensor([1]*len(word))\n",
    "    return word, attention_mask, negative_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('g', tensor(0.5295)), ('x', tensor(0.1003)), ('b', tensor(0.0660)), ('f', tensor(0.0640)), ('w', tensor(0.0614)), ('s', tensor(0.0521)), ('i', tensor(0.0335)), ('y', tensor(0.0284)), ('h', tensor(0.0109)), ('k', tensor(0.0098)), ('u', tensor(0.0080)), ('o', tensor(0.0072)), ('j', tensor(0.0057)), ('v', tensor(0.0053)), ('z', tensor(0.0044)), ('c', tensor(0.0037)), ('n', tensor(0.0033)), ('t', tensor(0.0027)), ('m', tensor(0.0025)), ('e', tensor(0.0003)), ('q', tensor(0.0002)), ('l', tensor(0.0002)), ('r', tensor(0.0002)), ('p', tensor(0.0002)), ('a', tensor(5.2482e-05)), ('d', tensor(1.6473e-05))]\n"
     ]
    }
   ],
   "source": [
    "word = \"pred_al\"\n",
    "negative_samples = list(\"predlnamcvt\")\n",
    "with torch.no_grad():\n",
    "    input_ids, attention_mask, negative_sample = tensorify(word, negative_samples)\n",
    "    idx = list(map(lambda x: x[0], filter(lambda x: x[1] == \"_\", enumerate(word))))\n",
    "    logits = model(\n",
    "        input_ids.unsqueeze(0),\n",
    "        attention_mask.unsqueeze(0),\n",
    "        negative_sample.unsqueeze(0),\n",
    "    )\n",
    "    topk = logits.squeeze()[idx].topk(26, dim=-1)\n",
    "    scores = torch.softmax(topk.values, dim=-1)\n",
    "    characters = [[idx2char[xx] for xx in x] for x in topk.indices.tolist()]\n",
    "    for i in range(len(scores)):\n",
    "        print(list(zip(characters[i], scores[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import random\n",
    "from typing import List\n",
    "from dataset import CharacterLevelTokenizer\n",
    "from collections import OrderedDict, defaultdict, namedtuple\n",
    "\n",
    "\n",
    "class HangmanBertPredictor:\n",
    "    def __init__(self, model_file: str, word_file: str) -> None:\n",
    "        self.model = torch.load(model_file, map_location='cuda')\n",
    "        self.model.eval()\n",
    "        with open(word_file, \"r\") as f:\n",
    "            self.words = f.read().split(\"\\n\")\n",
    "\n",
    "        self.tokenizer = CharacterLevelTokenizer(64)\n",
    "        self.vocab = self.tokenizer.vocab\n",
    "        self.idx2char = list(self.vocab.keys())\n",
    "\n",
    "    def get_a_random_word(self):\n",
    "        # random.seed(10)\n",
    "        idx = random.randint(0, len(self.words) - 1)\n",
    "        word = self.words[idx]\n",
    "        return word\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_from_word(\n",
    "        self, word: str, label: str, negative_sample: str\n",
    "    ) -> List[str]:\n",
    "        tokenized_word, _ = self.tokenizer.tokenize(word, label)\n",
    "        tokenized_word = tokenized_word.unsqueeze(0).cuda()\n",
    "        attention_mask = torch.ones_like(tokenized_word).cuda()\n",
    "        idx = tokenized_word == self.tokenizer.vocab[\"<PAD>\"]\n",
    "        attention_mask[idx] = 0\n",
    "        negative_sample_tensor = torch.tensor([0.0] * len(self.vocab))\n",
    "        negative_sample_tensor[[self.vocab[c] for c in set(negative_sample)]] = 1\n",
    "        negative_sample_tensor = negative_sample_tensor.unsqueeze(0).cuda()\n",
    "        output = torch.softmax(\n",
    "            self.model(tokenized_word, attention_mask, negative_sample_tensor), dim=-1\n",
    "        ).cpu()\n",
    "        idx = torch.tensor(list(map(lambda c: c != \"_\", word)))\n",
    "        output = output[0, : len(word)]\n",
    "        # print(output[~idx].shape)\n",
    "        scores = output[~idx]\n",
    "        indices = self.vocab.keys()\n",
    "        indices_n_scores = sorted(\n",
    "            zip(indices, scores.view(-1).tolist()), key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "\n",
    "        ordered_set = OrderedDict()\n",
    "\n",
    "        for k, v in indices_n_scores:\n",
    "            if k not in ordered_set:\n",
    "                ordered_set[k] = v\n",
    "\n",
    "        predictions = list(ordered_set.keys())\n",
    "        return predictions\n",
    "\n",
    "    def predict_n_steps(self, b):\n",
    "        rand_word = self.get_a_random_word()\n",
    "        og_word = rand_word\n",
    "        label = rand_word\n",
    "        rand_word = [\"_\"] * len(label)\n",
    "        labels_indexes = defaultdict(list)\n",
    "        gts = set(label)\n",
    "        for i, c in enumerate(label):\n",
    "            labels_indexes[c].append(i)\n",
    "        steps = 0\n",
    "        taken_steps = []\n",
    "        negative_sample = set()\n",
    "        while \"_\" in rand_word:\n",
    "            predictions = self.predict_from_word(rand_word, label, negative_sample)\n",
    "            # print(rand_word, predictions)\n",
    "            steps += 1\n",
    "            # hit\n",
    "            for c in predictions:\n",
    "                # hit\n",
    "                negative_sample.add(c)\n",
    "                if c in gts:\n",
    "                    for i in labels_indexes[c]:\n",
    "                        rand_word[i] = c\n",
    "                    taken_steps.append(rand_word[:])\n",
    "                    gts.remove(c)\n",
    "                    break\n",
    "        return og_word, steps, taken_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "hangman_bert_predictor = HangmanBertPredictor(\n",
    "    model_file='model.trained.pt',\n",
    "    word_file='words_250000_train.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:58<00:00, 17.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "steps_distribution = []\n",
    "for i in tqdm(range(1_000)):\n",
    "    og_word, steps, taken_steps = hangman_bert_predictor.predict_n_steps(None)\n",
    "    steps_distribution.append(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (6, 2)\n",
      "┌────────────┬──────────┐\n",
      "│ statistic  ┆ value    │\n",
      "│ ---        ┆ ---      │\n",
      "│ str        ┆ f64      │\n",
      "╞════════════╪══════════╡\n",
      "│ min        ┆ 1.0      │\n",
      "│ max        ┆ 13.0     │\n",
      "│ null_count ┆ 0.0      │\n",
      "│ mean       ┆ 7.406    │\n",
      "│ std        ┆ 2.008282 │\n",
      "│ count      ┆ 1000.0   │\n",
      "└────────────┴──────────┘\n",
      "0.1 5.0\n",
      "0.2 6.0\n",
      "0.3 6.0\n",
      "0.4 7.0\n",
      "0.5 7.0\n",
      "0.6 8.0\n",
      "0.7 8.0\n",
      "0.8 9.0\n",
      "0.9 10.0\n",
      "1.0 13.0\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "print(pl.Series(steps_distribution).describe())\n",
    "\n",
    "for i in range(1, 11):\n",
    "    print(i/10, pl.Series(steps_distribution).quantile(i/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt4r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f208ed1add73609b8776cd375976a3698f33d1aff53af83867f2a7312cae9c1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
